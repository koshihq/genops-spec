#!/usr/bin/env python3
"""
Hugging Face Multi-Provider Cost Tracking Example

This example demonstrates unified cost tracking across multiple AI providers
accessible through Hugging Face, including OpenAI, Anthropic, and Hub models.

Example usage:
    python multi_provider_costs.py

Features demonstrated:
- Multi-provider cost aggregation
- Provider comparison and optimization
- Unified governance across providers
- Cost attribution and reporting
- Budget-aware operations
"""

import sys
import os
import logging
from typing import Dict, List
from dataclasses import dataclass, field
from datetime import datetime

# Add src to path for development  
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class OperationCost:
    """Track cost details for a single AI operation."""
    operation_id: str
    provider: str
    model: str
    task: str
    input_tokens: int
    output_tokens: int
    cost: float
    timestamp: datetime = field(default_factory=datetime.now)
    governance_attrs: Dict[str, str] = field(default_factory=dict)

@dataclass  
class MultiProviderSession:
    """Track costs across multiple providers in a single session."""
    session_id: str
    operations: List[OperationCost] = field(default_factory=list)
    
    @property
    def total_cost(self) -> float:
        return sum(op.cost for op in self.operations)
    
    @property
    def cost_by_provider(self) -> Dict[str, float]:
        costs = {}
        for op in self.operations:
            costs[op.provider] = costs.get(op.provider, 0) + op.cost
        return costs
    
    @property
    def cost_by_model(self) -> Dict[str, float]:
        costs = {}
        for op in self.operations:
            costs[op.model] = costs.get(op.model, 0) + op.cost
        return costs
    
    def get_cost_breakdown(self) -> Dict[str, any]:
        return {
            "total_cost": self.total_cost,
            "cost_by_provider": self.cost_by_provider,
            "cost_by_model": self.cost_by_model,
            "operations_count": len(self.operations),
            "providers_used": list(set(op.provider for op in self.operations)),
            "models_used": list(set(op.model for op in self.operations))
        }


def demonstrate_multi_provider_operations():
    """Demonstrate operations across multiple providers with unified cost tracking."""
    
    print("ğŸŒ Multi-Provider Operations Demo")
    print("="*50)
    print("Demonstrating unified cost tracking across OpenAI, Anthropic, and Hub models")
    print()
    
    try:
        from genops.providers.huggingface import GenOpsHuggingFaceAdapter
        from genops.providers.huggingface_pricing import calculate_huggingface_cost
        
        adapter = GenOpsHuggingFaceAdapter()
        session = MultiProviderSession(session_id="multi-provider-demo-2024")
        
        # Define test operations across different providers
        operations_to_test = [
            {
                "name": "OpenAI Text Generation",
                "model": "gpt-3.5-turbo",
                "prompt": "Write a brief product description for an AI-powered analytics platform.",
                "task": "text-generation",
                "governance": {
                    "team": "product-team",
                    "project": "marketing-copy",
                    "customer_id": "saas-client-001"
                }
            },
            {
                "name": "Anthropic Chat Completion",
                "model": "claude-3-haiku",
                "prompt": "Provide customer support response for a billing inquiry.",
                "task": "chat-completion", 
                "governance": {
                    "team": "support-team",
                    "project": "customer-service-ai",
                    "customer_id": "support-internal"
                }
            },
            {
                "name": "Hub Model Text Generation",
                "model": "microsoft/DialoGPT-medium",
                "prompt": "Generate a casual conversation starter for a networking event.",
                "task": "text-generation",
                "governance": {
                    "team": "events-team",
                    "project": "networking-bot", 
                    "customer_id": "events-client-789"
                }
            },
            {
                "name": "Hub Model Embeddings",
                "model": "sentence-transformers/all-MiniLM-L6-v2",
                "prompt": "Transform customer feedback into searchable embeddings",
                "task": "feature-extraction",
                "governance": {
                    "team": "analytics-team",
                    "project": "feedback-analysis",
                    "customer_id": "analytics-internal"
                }
            }
        ]
        
        print("ğŸ“Š Running operations across multiple providers...")
        print()
        
        for i, operation in enumerate(operations_to_test, 1):
            print(f"   {i}. {operation['name']}:")
            print(f"      Model: {operation['model']}")
            
            # Detect provider for cost calculation
            provider = adapter.detect_provider_for_model(operation['model'])
            print(f"      Provider: {provider}")
            
            # Estimate tokens (in real usage, these would come from actual API calls)
            estimated_input_tokens = len(operation['prompt'].split()) * 4  # Rough estimate
            estimated_output_tokens = 100  # Typical response size
            
            # Calculate cost
            try:
                cost = calculate_huggingface_cost(
                    provider=provider,
                    model=operation['model'],
                    input_tokens=estimated_input_tokens,
                    output_tokens=estimated_output_tokens,
                    task=operation['task']
                )
                
                print(f"      Tokens: {estimated_input_tokens} in, {estimated_output_tokens} out")
                print(f"      Cost: ${cost:.6f}")
                
                # Record operation
                op_cost = OperationCost(
                    operation_id=f"op-{i:03d}",
                    provider=provider,
                    model=operation['model'],
                    task=operation['task'],
                    input_tokens=estimated_input_tokens,
                    output_tokens=estimated_output_tokens,
                    cost=cost,
                    governance_attrs=operation['governance']
                )
                session.operations.append(op_cost)
                
                print(f"      âœ… Cost tracked for {operation['governance']['team']}")
                
            except Exception as e:
                print(f"      âš ï¸ Cost calculation failed: {e}")
            
            print()
        
        # Try actual API calls (may fail due to rate limits/connectivity)
        print("ğŸš€ Attempting live API calls (may be limited by rate limits)...")
        live_successes = 0
        
        for operation in operations_to_test[:2]:  # Just try first 2 to avoid rate limits
            try:
                if operation['task'] == 'feature-extraction':
                    response = adapter.feature_extraction(
                        inputs=operation['prompt'],
                        model=operation['model'],
                        **operation['governance']
                    )
                    live_successes += 1
                    print(f"   âœ… {operation['name']} succeeded")
                    
                else:
                    response = adapter.text_generation(
                        prompt=operation['prompt'],
                        model=operation['model'], 
                        max_new_tokens=50,
                        **operation['governance']
                    )
                    live_successes += 1
                    print(f"   âœ… {operation['name']} succeeded")
                    print(f"      Response: {str(response)[:80]}...")
                    
            except Exception as e:
                print(f"   âš ï¸ {operation['name']} failed: {str(e)[:60]}...")
        
        print(f"\n   Live API Success Rate: {live_successes}/{min(2, len(operations_to_test))}")
        print()
        
        return session
        
    except ImportError as e:
        print(f"âŒ Import failed: {e}")
        return None


def analyze_cost_breakdown(session: MultiProviderSession):
    """Analyze and display cost breakdown across providers."""
    
    print("ğŸ’° Cost Analysis and Breakdown")
    print("="*40)
    
    breakdown = session.get_cost_breakdown()
    
    print(f"ğŸ“Š Session Summary:")
    print(f"   Total Operations: {breakdown['operations_count']}")
    print(f"   Providers Used: {len(breakdown['providers_used'])}")
    print(f"   Models Used: {len(breakdown['models_used'])}")
    print(f"   Total Cost: ${breakdown['total_cost']:.6f}")
    print()
    
    # Cost by provider
    print("ğŸ¢ Cost by Provider:")
    for provider, cost in breakdown['cost_by_provider'].items():
        percentage = (cost / breakdown['total_cost']) * 100 if breakdown['total_cost'] > 0 else 0
        provider_icon = {
            'openai': 'ğŸ¤–',
            'anthropic': 'ğŸ§ ', 
            'huggingface_hub': 'ğŸ¤—',
            'cohere': 'ğŸ”®',
            'mistral': 'ğŸŒŸ'
        }.get(provider, 'ğŸ”§')
        
        print(f"   {provider_icon} {provider:15} â†’ ${cost:8.6f} ({percentage:5.1f}%)")
    print()
    
    # Cost by model
    print("ğŸ¯ Cost by Model:")
    model_costs = sorted(breakdown['cost_by_model'].items(), key=lambda x: x[1], reverse=True)
    for model, cost in model_costs:
        percentage = (cost / breakdown['total_cost']) * 100 if breakdown['total_cost'] > 0 else 0
        print(f"   ğŸ“± {model[:30]:30} â†’ ${cost:8.6f} ({percentage:5.1f}%)")
    print()
    
    # Team attribution
    print("ğŸ‘¥ Cost Attribution by Team:")
    team_costs = {}
    for op in session.operations:
        team = op.governance_attrs.get('team', 'unknown')
        team_costs[team] = team_costs.get(team, 0) + op.cost
        
    for team, cost in sorted(team_costs.items(), key=lambda x: x[1], reverse=True):
        percentage = (cost / breakdown['total_cost']) * 100 if breakdown['total_cost'] > 0 else 0
        print(f"   ğŸ‘¥ {team:15} â†’ ${cost:8.6f} ({percentage:5.1f}%)")
    print()
    
    # Customer billing
    print("ğŸ¢ Customer Billing Attribution:")
    customer_costs = {}
    for op in session.operations:
        customer = op.governance_attrs.get('customer_id', 'internal')
        customer_costs[customer] = customer_costs.get(customer, 0) + op.cost
        
    for customer, cost in sorted(customer_costs.items(), key=lambda x: x[1], reverse=True):
        percentage = (cost / breakdown['total_cost']) * 100 if breakdown['total_cost'] > 0 else 0
        print(f"   ğŸ¢ {customer[:20]:20} â†’ ${cost:8.6f} ({percentage:5.1f}%)")
    print()


def demonstrate_cost_optimization():
    """Show cost optimization strategies across providers."""
    
    print("ğŸ¯ Cost Optimization Strategies")
    print("="*40)
    print("Demonstrating intelligent model selection for cost optimization:")
    print()
    
    try:
        from genops.providers.huggingface_pricing import (
            compare_model_costs,
            get_cost_optimization_suggestions
        )
        
        # Compare costs for similar tasks across providers
        print("ğŸ’¡ Model Cost Comparison for Similar Tasks:")
        print()
        
        # Text generation task comparison
        text_models = [
            "gpt-3.5-turbo",                    # OpenAI
            "claude-3-haiku",                   # Anthropic
            "microsoft/DialoGPT-medium",        # Hugging Face Hub
            "mistral-7b-instruct"               # Mistral
        ]
        
        print("   ğŸ“ Text Generation (1000 input, 500 output tokens):")
        text_comparison = compare_model_costs(text_models, input_tokens=1000, output_tokens=500)
        
        cheapest_cost = min(info['cost'] for info in text_comparison.values())
        
        for model, info in text_comparison.items():
            cost_tier = "ğŸ’°" if info['cost'] > cheapest_cost * 3 else "ğŸ’›" if info['cost'] > cheapest_cost * 1.5 else "ğŸ’š"
            savings = ((info['cost'] - cheapest_cost) / cheapest_cost * 100) if cheapest_cost > 0 else 0
            
            print(f"      {cost_tier} {model[:35]:35} â†’ ${info['cost']:8.6f} ({info['relative_cost']:4.1f}x)")
            if savings > 0:
                print(f"         ğŸ’¸ ${info['cost'] - cheapest_cost:8.6f} more expensive ({savings:+5.1f}%)")
        print()
        
        # Embedding task comparison  
        embedding_models = [
            "text-embedding-ada-002",                    # OpenAI
            "sentence-transformers/all-MiniLM-L6-v2",    # Hugging Face Hub
            "embed-english-v3.0"                        # Cohere
        ]
        
        print("   ğŸ” Embeddings/Feature Extraction (1000 input tokens):")
        embedding_comparison = compare_model_costs(
            embedding_models, 
            input_tokens=1000, 
            output_tokens=0, 
            task="feature-extraction"
        )
        
        cheapest_embedding = min(info['cost'] for info in embedding_comparison.values())
        
        for model, info in embedding_comparison.items():
            cost_tier = "ğŸ’°" if info['cost'] > cheapest_embedding * 2 else "ğŸ’š"
            print(f"      {cost_tier} {model[:35]:35} â†’ ${info['cost']:8.6f} ({info['relative_cost']:4.1f}x)")
        print()
        
        # Cost optimization suggestions
        print("ğŸ§  Intelligent Cost Optimization Suggestions:")
        
        expensive_model = "gpt-4"  # Example expensive model
        suggestions = get_cost_optimization_suggestions(expensive_model, "text-generation")
        
        print(f"   Current model: {suggestions['current_model']['model']}")
        print(f"   Current cost: ${suggestions['current_model']['cost_per_1k']['input']:.6f} per 1K input tokens")
        print()
        
        print("   ğŸ’¡ Optimization recommendations:")
        for tip in suggestions['optimization_tips']:
            print(f"      â€¢ {tip}")
        print()
        
        if suggestions['alternatives']:
            print("   ğŸ”„ Alternative models:")
            for alt in suggestions['alternatives'][:3]:  # Show top 3 alternatives
                savings = alt.get('savings', 0)
                print(f"      ğŸ’š {alt['model'][:30]:30} â†’ {savings:5.1f}% cost savings")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Cost optimization unavailable: {e}")
        return False


def demonstrate_budget_aware_operations():
    """Show budget-aware operation strategies."""
    
    print("ğŸ’³ Budget-Aware Operations")
    print("="*35)
    print("Demonstrating operations that respect budget constraints:")
    print()
    
    # Simulated budget constraints
    budgets = {
        "product-team": 10.00,      # $10 daily budget
        "support-team": 25.00,      # $25 daily budget  
        "analytics-team": 5.00,     # $5 daily budget
    }
    
    # Current usage (simulated)
    current_usage = {
        "product-team": 7.50,       # $7.50 used
        "support-team": 18.75,      # $18.75 used
        "analytics-team": 4.20,     # $4.20 used
    }
    
    print("ğŸ“Š Budget Status:")
    for team in budgets:
        budget = budgets[team]
        used = current_usage[team]
        remaining = budget - used
        usage_pct = (used / budget) * 100
        
        status_icon = "ğŸ”´" if remaining < 1 else "ğŸŸ¡" if usage_pct > 75 else "ğŸŸ¢"
        
        print(f"   {status_icon} {team:15} â†’ ${used:6.2f} / ${budget:6.2f} ({usage_pct:5.1f}%) - ${remaining:6.2f} remaining")
    print()
    
    # Budget-aware model selection
    print("ğŸ¯ Budget-Aware Model Selection:")
    
    tasks_to_consider = [
        {
            "team": "product-team",
            "task": "Generate product feature description (200 tokens expected)",
            "estimated_tokens": 200,
            "models_to_consider": ["gpt-4", "gpt-3.5-turbo", "microsoft/DialoGPT-medium"]
        },
        {
            "team": "support-team", 
            "task": "Customer support response (150 tokens expected)",
            "estimated_tokens": 150,
            "models_to_consider": ["claude-3-opus", "claude-3-haiku", "microsoft/DialoGPT-medium"]
        },
        {
            "team": "analytics-team",
            "task": "Text embeddings for analysis (500 tokens)",
            "estimated_tokens": 500,
            "models_to_consider": ["text-embedding-ada-002", "sentence-transformers/all-MiniLM-L6-v2"]
        }
    ]
    
    try:
        from genops.providers.huggingface_pricing import calculate_huggingface_cost
        from genops.providers.huggingface import GenOpsHuggingFaceAdapter
        
        adapter = GenOpsHuggingFaceAdapter()
        
        for task in tasks_to_consider:
            team = task['team']
            remaining_budget = budgets[team] - current_usage[team]
            
            print(f"   ğŸ‘¥ {team} (${remaining_budget:.2f} remaining):")
            print(f"      Task: {task['task']}")
            
            # Evaluate models within budget
            affordable_models = []
            
            for model in task['models_to_consider']:
                provider = adapter.detect_provider_for_model(model)
                estimated_cost = calculate_huggingface_cost(
                    provider=provider,
                    model=model,
                    input_tokens=task['estimated_tokens'],
                    output_tokens=task['estimated_tokens'] // 2,  # Estimate output
                    task="text-generation"
                )
                
                within_budget = estimated_cost <= remaining_budget
                status = "âœ…" if within_budget else "âŒ"
                budget_indicator = "WITHIN BUDGET" if within_budget else "OVER BUDGET"
                
                print(f"         {status} {model[:30]:30} â†’ ${estimated_cost:.6f} ({budget_indicator})")
                
                if within_budget:
                    affordable_models.append((model, estimated_cost))
            
            if affordable_models:
                # Recommend cheapest available option
                cheapest = min(affordable_models, key=lambda x: x[1])
                print(f"         ğŸ’¡ Recommended: {cheapest[0]} (${cheapest[1]:.6f})")
            else:
                print(f"         âš ï¸  All models over budget - consider cost optimization")
            
            print()
        
        print("âœ… Budget-aware selection helps teams stay within cost constraints")
        print("âœ… Real-time budget tracking enables proactive cost management")
        print()
        
        return True
        
    except ImportError:
        print("âŒ Budget analysis unavailable - check installation")
        return False


def main():
    """Main demonstration function."""
    
    print("Welcome to the Multi-Provider Cost Tracking Demo!")
    print()
    print("This example demonstrates comprehensive cost tracking and optimization")
    print("across multiple AI providers accessible through Hugging Face.")
    print()
    
    success_count = 0
    
    # Run multi-provider operations demo
    print("ğŸš€ Running Multi-Provider Operations Demo...")
    session = demonstrate_multi_provider_operations()
    if session and len(session.operations) > 0:
        success_count += 1
        print("âœ… Multi-provider operations demo completed successfully")
        print()
        
        # Analyze the results
        analyze_cost_breakdown(session)
        print("-" * 60)
    else:
        print("âš ï¸ Multi-provider operations demo had issues")
        print()
    
    # Cost optimization demo
    print("ğŸš€ Running Cost Optimization Demo...")
    if demonstrate_cost_optimization():
        success_count += 1
        print("âœ… Cost optimization demo completed successfully")
    else:
        print("âš ï¸ Cost optimization demo had issues")
    print("-" * 60)
    
    # Budget-aware operations demo
    print("ğŸš€ Running Budget-Aware Operations Demo...")
    if demonstrate_budget_aware_operations():
        success_count += 1
        print("âœ… Budget-aware operations demo completed successfully")
    else:
        print("âš ï¸ Budget-aware operations demo had issues")
    print("-" * 60)
    print()
    
    # Summary
    if success_count >= 2:
        print("ğŸ‰ Multi-Provider Cost Tracking Demo Completed Successfully!")
        print()
        print("ğŸš€ Key Takeaways:")
        print("   âœ… Unified cost tracking across OpenAI, Anthropic, and Hub models")
        print("   âœ… Real-time provider detection and cost calculation")
        print("   âœ… Team and customer cost attribution for billing")
        print("   âœ… Cost optimization recommendations")
        print("   âœ… Budget-aware operation strategies")
        print()
        print("ğŸš€ Next Steps:")
        print("   1. Set up OpenTelemetry export for production cost tracking")
        print("   2. Implement budget alerts and enforcement policies")
        print("   3. Try ai_task_examples.py for comprehensive task coverage")
        print("   4. Explore production_patterns.py for enterprise deployment")
        
    else:
        print("âš ï¸ Multi-provider demo encountered multiple issues")
        print("   Check setup_validation.py and internet connectivity")
    
    return 0 if success_count >= 2 else 1


if __name__ == "__main__":
    sys.exit(main())